{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da68d622",
   "metadata": {},
   "source": [
    "# Agent\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a router.\n",
    "\n",
    "* Our chat model will decide to make a tool call or not based upon the user input\n",
    "* We use a conditional edge to route to a node that will call our tool or simply end\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, we can extend this into a generic agent architecture.\n",
    "\n",
    "In the above router, we invoked the model and, if it chose to call a tool, we returned a `ToolMessage` to the user.\n",
    " \n",
    "But, what if we simply pass that `ToolMessage` *back to the model*?\n",
    "\n",
    "We can let it either (1) call another tool or (2) respond directly.\n",
    "\n",
    "This is the intuition behind [ReAct](https://react-lm.github.io/), a general agent architecture.\n",
    "  \n",
    "* `act` - let the model call specific tools \n",
    "* `observe` - pass the tool output back to the model \n",
    "* `reason` - let the model reason about the tool output to decide what to do next (e.g., call another tool or just respond directly)\n",
    "\n",
    "This [general purpose architecture](https://blog.langchain.dev/planning-for-agents/) can be applied to many types of tools. \n",
    "\n",
    "![Screenshot 2024-08-21 at 12.45.43 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbac0b4a2c1e5e02f3e78b_agent2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea33c875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45de840",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ae8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we set parallel tool calling to false as math generally is done sequentially\n",
    "# the OpenAI model specifically defaults to parallel tool calling for efficiency, see https://python.langchain.com/docs/how_to/tool_calling_parallel/\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo-0125', parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b262e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tools\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b\n",
    "    \n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "\n",
    "tools = [multiply, add, divide]\n",
    "# bind the tool\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eee1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd1c027a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node('tool_calling_llm', tool_calling_llm) \n",
    "builder.add_node('tools', ToolNode(tools)) # create the node that runs 'multiply' tool\n",
    "\n",
    "\n",
    "builder.add_edge(START, 'tool_calling_llm')\n",
    "builder.add_conditional_edges(\n",
    "    'tool_calling_llm',\n",
    "    tools_condition # to check if the last message has tool calls.\n",
    ")\n",
    "builder.add_edge('tools','tool_calling_llm')\n",
    "\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b0d4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Add 3 and 4. Multiply the output by 2. Divide the output by 5\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "822c0e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4. Multiply the output by 2. Divide the output by 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_ETnJG7pa9uzk5ZEFPWACBPzK)\n",
      " Call ID: call_ETnJG7pa9uzk5ZEFPWACBPzK\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_dSzNUxgMtoRtYipogg3G4pid)\n",
      " Call ID: call_dSzNUxgMtoRtYipogg3G4pid\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (call_U0EGu9RX3YfQAaimcIqlBydy)\n",
      " Call ID: call_U0EGu9RX3YfQAaimcIqlBydy\n",
      "  Args:\n",
      "    a: 14\n",
      "    b: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide\n",
      "\n",
      "null\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The final result after performing the operations is 2.8.\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148527c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9c29988",
   "metadata": {},
   "source": [
    "Here, we'll use [LangSmith](https://docs.smith.langchain.com/) for [tracing](https://docs.smith.langchain.com/concepts/tracing).\n",
    "\n",
    "We'll log to a project, `langchain-academy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157c340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a7d3683",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "Now, we're going extend our agent by introducing memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb23397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_Zr4pOzMIreuX3UgxCHiuqclN)\n",
      " Call ID: call_Zr4pOzMIreuX3UgxCHiuqclN\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f24c477b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_XP2o2t3PKPeIsSyoDpGp3Nrh)\n",
      " Call ID: call_XP2o2t3PKPeIsSyoDpGp3Nrh\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "4\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 by 2 is 4.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiply that by 2.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f72c4a",
   "metadata": {},
   "source": [
    "We don't retain memory of 7 from our initial chat!\n",
    "\n",
    "This is because [state is transient](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220) to a single graph execution.\n",
    "We can use [persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) to address this! \n",
    "\n",
    "LangGraph can use a checkpointer to automatically save the graph state after each step.\n",
    "* This built-in persistence layer gives us memory, allowing LangGraph to pick up from the last state update. \n",
    "* One of the easiest checkpointers to use is the `MemorySaver`, an in-memory key-value store for Graph state.\n",
    "\n",
    "All we need to do is simply compile the graph with a checkpointer, and our graph has memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8dddc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a491862",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = MemorySaver()\n",
    "\n",
    "react_graph_memory = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a4d11b",
   "metadata": {},
   "source": [
    "When we use memory, we need to specify a `thread_id`.\n",
    "\n",
    "This `thread_id` will store our collection of graph states.\n",
    "\n",
    "Here is a cartoon:\n",
    "\n",
    "* The checkpointer write the state at every step of the graph\n",
    "* These checkpoints are saved in a thread \n",
    "* We can access that thread in the future using the `thread_id`\n",
    "\n",
    "![state.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e0e9f526b41a4ed9e2d28b_agent-memory2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c32d61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_c6E67hNiOmudBdGATxpYIavP)\n",
      " Call ID: call_c6E67hNiOmudBdGATxpYIavP\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n"
     ]
    }
   ],
   "source": [
    "# Specify a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "\n",
    "# Run\n",
    "messages = react_graph_memory.invoke({\"messages\": messages},config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1231df89",
   "metadata": {},
   "source": [
    "If we pass the same `thread_id`, then we can proceed from from the previously logged state checkpoint! \n",
    "\n",
    "In this case, the above conversation is captured in the thread.\n",
    "\n",
    "The `HumanMessage` we pass (`\"Multiply that by 2.\"`) is appended to the above conversation.\n",
    "\n",
    "So, the model now know that `that` refers to the `The sum of 3 and 4 is 7.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85d6e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_c6E67hNiOmudBdGATxpYIavP)\n",
      " Call ID: call_c6E67hNiOmudBdGATxpYIavP\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_Q07xE2sSxsqGh1e4n7F5jhfu)\n",
      " Call ID: call_Q07xE2sSxsqGh1e4n7F5jhfu\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "When you multiply the sum of 3 and 4 by 2, you get 14.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiply that by 2.\")]\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7906de1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58129157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_euMN6nogaPTQ52oTkaYXM5ON)\n",
      " Call ID: call_euMN6nogaPTQ52oTkaYXM5ON\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "4\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 by 2 is 4.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiply that by 2.\")]\n",
    "\n",
    "config1 = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "# if we use a different 'thread_id', then the agent does not remember previous\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config1)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45f46e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_c6E67hNiOmudBdGATxpYIavP)\n",
      " Call ID: call_c6E67hNiOmudBdGATxpYIavP\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The sum of 3 and 4 is 7.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_Q07xE2sSxsqGh1e4n7F5jhfu)\n",
      " Call ID: call_Q07xE2sSxsqGh1e4n7F5jhfu\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "When you multiply the sum of 3 and 4 by 2, you get 14.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_6ZOzO7tv2cVgiijll1lI2eAe)\n",
      " Call ID: call_6ZOzO7tv2cVgiijll1lI2eAe\n",
      "  Args:\n",
      "    a: 14\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "28\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "When you multiply the result 14 by 2, you get 28.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiply that by 2.\")]\n",
    "\n",
    "# if we use a different 'thread_id', then the agent does not remember previous\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff79f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "lc-academy-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
