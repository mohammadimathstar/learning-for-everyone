{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f165044-e139-41de-b01b-2ab35f528c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97c2b1-e7ed-4d70-aa24-dc51a188fe56",
   "metadata": {},
   "source": [
    "## Branching\n",
    "\n",
    "Here, we would like to create a system which:\n",
    "* first, it takes the feedback (from a customer)\n",
    "* second, categorize the feedback (positive/negative/neutral),\n",
    "* lastly, based on the customer's feedback it answer the customer.\n",
    "\n",
    "For this, we need to have something called branching (if statement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049372a3-f2a8-4c4e-b8c9-fbade44b3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba95302-d95c-42dd-a714-79a44bab3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LLM model\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo-0125', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eca47da-3fd2-4b39-be06-dc1cc881a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt template\n",
    "# classification prompt\n",
    "classification_prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', 'you are a helpful assistant.'),\n",
    "        ('user', \"Classify the sentiment of the following feedback as positive, negative, neutral, or escalate {feedback}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "positive_feedback_template = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', 'you are a helpful assistant.'),\n",
    "        ('user', \"generate a thank you message to this positive feedback {feedback}\")\n",
    "    ]\n",
    ")\n",
    "negative_feedback_template = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', 'you are a helpful assistant.'),\n",
    "        ('user', \"generate a response to this negative feedback {feedback}\")\n",
    "    ]\n",
    ")\n",
    "neutral_feedback_template = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', 'you are a helpful assistant.'),\n",
    "        ('user', \"generate a message and ask more details for this neutral feedback {feedback}\")\n",
    "    ]\n",
    ")\n",
    "escalate_feedback_template = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', 'you are a helpful assistant.'),\n",
    "        ('user', \"generate a message to escalate this feedback to a human agent {feedback}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36da59c3-02ba-4e10-87c0-a9fcb90b774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "496f47a7-72b3-488c-8d27-554feff51d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a chain to classify the sentiment\n",
    "classification = classification_prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# define a runnable branch to handle different types of feedback\n",
    "branches = RunnableBranch(\n",
    "    (\n",
    "        lambda x: 'positive' in x,\n",
    "        positive_feedback_template | llm | StrOutputParser()\n",
    "    ),\n",
    "    (\n",
    "        lambda x: 'negative' in x,\n",
    "        negative_feedback_template | llm | StrOutputParser()\n",
    "    ),\n",
    "    (\n",
    "        lambda x: 'neutral' in x,\n",
    "        neutral_feedback_template | llm | StrOutputParser()\n",
    "    ),\n",
    "    escalate_feedback_template | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1f7fa2-1bfc-41b2-9ede-819069e687c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine classification chain with runnable branch\n",
    "chain = classification | branches"
   ]
  },
  {
   "cell_type": "raw",
   "id": "723f0117-af97-433d-bbee-5779727a70fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6f12ad-7b56-4d4a-b41a-e54b8f3a0985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry to hear that you are not satisfied with your experience. Your feedback is important to us, and we would like to understand more about your concerns so that we can address them effectively. Please feel free to provide more details or suggestions on how we can improve. Thank you for sharing your thoughts with us.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"I bought a new laptop and it does not work well.\"\n",
    "chain.invoke({'feedback': review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890770f-b9d5-4013-a160-ebabb8b9a87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9439e-adf3-4095-b25d-2f39d27e8cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e7766-c131-4f3d-9c57-0fea2ddd6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299b28a-6318-42a5-8b49-6cf39f5d90d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79791834-fc11-49a4-9e9a-5422fd0a2186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9a026-0c36-440a-b5e2-a9b7f9ad7657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-langchain",
   "language": "python",
   "name": "llm-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
