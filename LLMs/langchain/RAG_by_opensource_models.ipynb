{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7388c066-bd9f-4bc7-a015-15528266137a",
   "metadata": {},
   "source": [
    "# Building RAG applications using Open Source models\n",
    "\n",
    "## 1. Preparing the local model\n",
    "\n",
    "### 1-1. Install `Ollama` \n",
    "\n",
    "To install `Ollama` on your laptop, use the instruction for [installation](https://ollama.com/download).\n",
    "\n",
    "After installing it, you can search on its [website](https://ollama.com/) to learn which LLMs are available. Knowing the model, you can then download it through the following command in the terminal window:\n",
    "\n",
    "```\n",
    "ollama pull <model_name>\n",
    "```\n",
    "Note that here we use `llama2` model. \n",
    "\n",
    "You can then check what models you have on your laptop through:\n",
    "\n",
    "```\n",
    "ollama list\n",
    "```\n",
    "\n",
    "### 1-2. Install `langchain_ollama`\n",
    "\n",
    "As we want to use LangChain to construct the RAG application, we should install the related package (`langchain_ollama`) using `pip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9c6505d-db3a-425f-b32a-103ed5a44f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU langchain_ollama\n",
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af42d84f-22f5-4029-afa6-612485e829fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe first man on the moon was Neil Armstrong. He stepped foot on the lunar surface on July 20, 1969, as part of the Apollo 11 mission. Armstrong famously declared \"That\\'s one small step for man, one giant leap for mankind\" as he became the first person to walk on the moon.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OllamaLLM(model=\"llama2\")\n",
    "\n",
    "# to test the model\n",
    "llm.invoke(\"The first man on the moon was ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00abbe2e-4195-4058-8acb-332fb73ad887",
   "metadata": {},
   "source": [
    "## 2. Create a database\n",
    "\n",
    "Now, we need to create a database containing the vector embeddings of different part of the document. In order to do that, we need to do the following steps:\n",
    "* Load the document\n",
    "* Split it into smaller chunk\n",
    "* Create the vector embeddings of different chunk and save it in a database\n",
    "\n",
    "### 2-1. Load the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0acd9ac1-edbd-4832-8451-20b8f05fd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader #WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3b690d0-d367-4397-86ff-66d64899fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15 chunks.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "# loader = WebBaseLoader('https://en.wikipedia.org/wiki/Albert_Einstein')\n",
    "loader = PyPDFLoader('data/caselaw_1.pdf') # if you have a pdf document\n",
    "documents = loader.load_and_split(text_splitter)\n",
    "print(f\"There are {len(documents)} chunks.\")\n",
    "# documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365feb6-1089-4c58-9a43-a92a7366210f",
   "metadata": {},
   "source": [
    "### 2-2. Save documents in a Vector Store\n",
    "\n",
    "In order to extract relevant information (from the documents) to a question, we need to \n",
    "* save vector embeddings of documents in a vector store,\n",
    "* create a retriever which can extract the most relevant chunks to a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a34a3a5-8322-4b4c-9be2-78feb341774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1534be13-9d9d-4f6f-a60f-741a7e6b589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = DocArrayInMemorySearch.from_documents(\n",
    "    documents,\n",
    "    embedding=OllamaEmbeddings(model=\"llama2\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23c771a6-6d08-409b-877c-5de65431f6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.  On 11 November 2011 the police opened a criminal case under \\nArticle 122 (infliction of bodily injuries of medium severity) of the Criminal \\nCode. Following the investigations conducted into the case, the case file was \\nsent to a court, P. being charged under Article 121 (infliction of grave \\ninjuries) of the Criminal Code.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "res = retriever.invoke(\"which articles have been addressed?\")\n",
    "res[0].page_content[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b0200-7793-41b3-a29b-1de67211538c",
   "metadata": {},
   "source": [
    "## 3. Create the RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbc86d8f-3741-4f89-93f9-7b5193fb0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28889084-4c21-4f28-8585-9f205016caf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't \n",
      "answer the question, reply \"I don't know\".\n",
      "\n",
      "Context: Some context\n",
      "\n",
      "Question: here is the question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining the prompt template\n",
    "prompt_template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "print(prompt.format(context='Some context', question='here is the question'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7be4a028-8542-47c1-b2d7-c74cc7b51170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21072/3173368601.py:2: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  chain.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
       "  'question': {'title': 'Question', 'type': 'string'}},\n",
       " 'required': ['context', 'question'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb87763d-8a11-4466-80e8-31d01ba290ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Of course! Albert Einstein was a brilliant physicist and mathematician, but he was also skilled in other areas. Here are three subjects that he was particularly talented in:\\n\\n1. Mathematics: Einstein was known for his exceptional mathematical abilities, particularly in the area of differential equations and relativity. He often used mathematical models to describe his theories of physics, and his work in this area laid the foundation for modern mathematics.\\n2. Physics: As mentioned earlier, Einstein is best known for his work in physics, specifically his theory of relativity. However, he also made significant contributions to other areas of physics, including thermodynamics, electromagnetism, and quantum mechanics.\\n3. Language: Einstein was fluent in several languages, including German, English, French, and Italian. He was known to be particularly skilled in his native language, German, and he often used his knowledge of language to help him communicate complex scientific ideas more easily.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As it can be seen in 'required', the input should contain 'context' and 'question'\n",
    "chain.invoke({\n",
    "    'context': 'We are talking about Albert Einstein.',\n",
    "    'question': 'What subjects was he good at? Give me at least three subjects.'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56431b9c-2933-437f-9346-bf7c2ce2b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6897286e-0894-4053-ac83-c6620e4a71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a chain which can reply our questions based on the context\n",
    "chain = (\n",
    "    {\n",
    "        'context': itemgetter('question') | retriever, # here we send the query to the retriever to extract the most relevant chunks (or documents)\n",
    "        'question': itemgetter('question')\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "533e92dd-320a-497f-919d-15ebbc9fb69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context provided, the country that was respondent in the case is Ukraine.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    'question':\"Which country was the respondent?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35f7c70a-b07c-43ab-818b-4baf222ce20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context provided, the judgment date for this case law is:\\n\\n11 November 2011\\n\\nThis is indicated in the passage as \"On 11 November 2011 the police opened a criminal case under Article 122 (infliction of bodily injuries of medium severity) of the Criminal Code.\"'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    'question': 'when was the judgment date for this case law?'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9fbf0bbc-a118-437a-801b-43a33b2788d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided case law, the following ECHR articles have been addressed:\\n\\n* Article 3 of the Convention - procedural limb (para. 21)\\n* Article 41 of the Convention (para. 5)'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    'question': 'which articles from ECHR have been addressed in this case law?'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3fe4ac09-02f6-4f1e-9aa0-60d48f123c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm happy to help! However, I don't have access to external documents or websites, so I can't answer your question based on the provided context. The case law appears to be referring to specific previous cases, but I don't have the information to generate a list of those cases in JSON format.\\n\\nIf you provide me with more context or information about the case law, such as the names of the cases or the relevant pages, I may be able to help you better.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    'question': 'Give me the list of all previous cases cited by this case law in the json format?'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d6b86-a3af-489f-8ca5-bd7eebc3a600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727d671-8539-4f24-b23a-c9e9f2d4417b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de26c9c-51e9-4df2-bb31-73d2b355000f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c6532-00fc-4067-937a-135f32c04cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf5403-f7b3-48b7-88c7-0e4054faffd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-langchain",
   "language": "python",
   "name": "llm-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
